---
title: "require-llm-output-encoding"
description: "Require encoding of LLM outputs based on usage context."
copyright: (c) 2025 Ofri Peretz. All rights reserved.
---

import { FalseNegativeCTA, WhenNotToUse } from "@/components/RuleComponents";

Require encoding of LLM outputs based on usage context.

**OWASP LLM Top 10 2025**: LLM05 - Improper Output Handling  
**CWE**: [CWE-116](https://cwe.mitre.org/data/definitions/116.html)  
**Severity**: üî¥ Critical

## Rule Details

Enforces proper encoding of LLM outputs before use in HTML, SQL, or other contexts.

### ‚ùå Incorrect

```typescript
element.innerHTML = llmOutput;
db.query(`SELECT * FROM users WHERE name = '${llmOutput}'`);
```

### ‚úÖ Correct

```typescript
const safe = escapeHTML(llmOutput);
element.innerHTML = safe;

db.query('SELECT * FROM users WHERE name = ?', [llmOutput]);
```

## Options

```json
{
  "secure-coding/require-llm-output-encoding": ["error"]
}
```

## Best Practices

- **HTML**: Use `escapeHTML()` or set `textContent` instead of `innerHTML`
- **SQL**: Use parameterized queries
- **Shell**: Avoid if possible, or use proper escaping

## Version

Introduced in v2.3.0

<WhenNotToUse />

<FalseNegativeCTA />

## Known False Negatives

The following patterns are **not detected** due to static analysis limitations:

### Prompt from Variable

**Why**: Prompt content from variables not traced.

```typescript
// ‚ùå NOT DETECTED - Prompt from variable
const prompt = buildPrompt(userInput);
await generateText({ prompt });
```

**Mitigation**: Validate all prompt components.

### Nested Context

**Why**: Deep nesting obscures injection.

```typescript
// ‚ùå NOT DETECTED - Nested
const messages = [{ role: 'user', content: userInput }];
await chat({ messages });
```

**Mitigation**: Validate at all levels.

### Custom AI Wrappers

**Why**: Custom AI clients not recognized.

```typescript
// ‚ùå NOT DETECTED - Custom wrapper
myAI.complete(userPrompt);
```

**Mitigation**: Apply rule to wrapper implementations.